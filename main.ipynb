{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cde7704f-bd27-4975-8d92-3eaca6f76aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# dataset donwload\n",
    "from torchvision import datasets\n",
    "# data_folder = '~/cifar10/cifar/' \n",
    "data_folder = '~/workspace/data/cifar'\n",
    "# datasets.CIFAR10(data_folder, download=True)\n",
    "\n",
    "# \n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader \n",
    "class Colorize(torchvision.datasets.CIFAR10):\n",
    "    def __init__(self, root, train):\n",
    "        super().__init__(root, train)\n",
    "        \n",
    "    def __getitem__(self, ix):\n",
    "        im, _ = super().__getitem__(ix)\n",
    "        bw = im.convert('L').convert('RGB')\n",
    "        bw, im = np.array(bw)/255., np.array(im)/255. \n",
    "        bw, im = [torch.tensor(i).permute(2,0,1).to(device).float() for i in [bw,im]]\n",
    "        return bw, im\n",
    "\n",
    "trdt = Colorize(data_folder, train=True)\n",
    "valdt = Colorize(data_folder, train=False)\n",
    "\n",
    "trdl = DataLoader(trdt, batch_size=256, shuffle=True)\n",
    "valdl = DataLoader(valdt, batch_size=256, shuffle=False)\n",
    "\n",
    "from model import get_model\n",
    "\n",
    "model = get_model('unet')\n",
    "\n",
    "from torch import nn\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "903862f2-68ea-4a17-bdd5-21c54fb933fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "def train(dl,model,lossf,opt,device='cuda'):\n",
    "    model.train()\n",
    "    for x,y in tqdm(dl):\n",
    "        x,y = x.to(device),y.to(device)\n",
    "        opt.zero_grad()\n",
    "        pre = model(x)\n",
    "        loss = lossf(pre,y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(dl,model,lossf,epoch=None,exist_acc=True,device='cuda'):\n",
    "    model.eval()\n",
    "    size, acc , losses = len(dl.dataset) ,0,0\n",
    "    with torch.no_grad():\n",
    "        for x,y in tqdm(dl):\n",
    "            x,y = x.to(device),y.to(device)\n",
    "            pre = model(x)\n",
    "            loss = lossf(pre,y)\n",
    "            \n",
    "            if exist_acc: \n",
    "                acc += (pre.argmax(1)==y).type(torch.float).sum().item()\n",
    "            losses += loss.item()\n",
    "    if exist_acc:\n",
    "        accuracy = round(acc/size,4)\n",
    "    else:\n",
    "        accuracy = None\n",
    "    val_loss = round(losses/size,6)\n",
    "    print(f'[{epoch}] acc/loss: {accuracy}/{val_loss}' if exist_acc else f'[{epoch}] loss: {val_loss}')\n",
    "    return accuracy,val_loss \n",
    "\n",
    "import copy\n",
    "def run(trdl,valdl,model,loss,opt,sched,epoch=100,patience = 5,exist_acc=False,device='cuda'):\n",
    "    val_losses = {0:1}\n",
    "    model = model.to(device)\n",
    "    for i in range(epoch):\n",
    "        train(trdl,model,loss,opt,device=device)\n",
    "        acc,val_loss = test(valdl,model,loss,epoch=i,exist_acc=exist_acc,device=device)\n",
    "\n",
    "\n",
    "        if min(val_losses.values() ) > val_loss:\n",
    "            val_losses[i] = val_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "        if i == min(val_losses,key=val_losses.get)+patience:\n",
    "            break\n",
    "            \n",
    "        sched.step()\n",
    "    return best_model,val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e2afd78-7f59-468f-a431-0c94030bf4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [00:32<00:00,  5.95it/s]\n",
      "100%|██████████| 40/40 [00:03<00:00, 12.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] loss: 2.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [00:33<00:00,  5.90it/s]\n",
      "100%|██████████| 40/40 [00:03<00:00, 12.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 2.3e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [00:33<00:00,  5.93it/s]\n",
      "100%|██████████| 40/40 [00:03<00:00, 12.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] loss: 2.1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [00:32<00:00,  5.94it/s]\n",
      "100%|██████████| 40/40 [00:03<00:00, 12.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] loss: 2.1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [00:32<00:00,  5.95it/s]\n",
      "100%|██████████| 40/40 [00:03<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] loss: 2.4e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [00:32<00:00,  5.94it/s]\n",
      "100%|██████████| 40/40 [00:03<00:00, 12.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] loss: 2.3e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [00:33<00:00,  5.93it/s]\n",
      "100%|██████████| 40/40 [00:03<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6] loss: 2.2e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [00:33<00:00,  5.92it/s]\n",
      "100%|██████████| 40/40 [00:03<00:00, 12.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7] loss: 2e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [00:33<00:00,  5.94it/s]\n",
      "100%|██████████| 40/40 [00:03<00:00, 12.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8] loss: 2.4e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [00:33<00:00,  5.90it/s]\n",
      "100%|██████████| 40/40 [00:03<00:00, 12.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9] loss: 2.1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [00:33<00:00,  5.93it/s]\n",
      "100%|██████████| 40/40 [00:03<00:00, 12.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10] loss: 1.9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [00:33<00:00,  5.90it/s]\n",
      "100%|██████████| 40/40 [00:03<00:00, 12.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11] loss: 1.9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [00:33<00:00,  5.90it/s]\n",
      "100%|██████████| 40/40 [00:03<00:00, 12.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12] loss: 1.9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [00:32<00:00,  5.95it/s]\n",
      "100%|██████████| 40/40 [00:03<00:00, 12.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13] loss: 1.9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [00:32<00:00,  5.94it/s]\n",
      "100%|██████████| 40/40 [00:03<00:00, 12.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14] loss: 1.9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [00:32<00:00,  5.94it/s]\n",
      "100%|██████████| 40/40 [00:03<00:00, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15] loss: 1.9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_model,val_losses = run(trdl,valdl,model,loss_fn,opt,scheduler,epoch=100,device=device) #,exist_acc=config['exist_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3858b95-4224-49de-9760-799de9d79cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (d1): DownConv(\n",
       "    (model): Sequential(\n",
       "      (0): Identity()\n",
       "      (1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (d2): DownConv(\n",
       "    (model): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (d3): DownConv(\n",
       "    (model): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (d4): DownConv(\n",
       "    (model): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (d5): DownConv(\n",
       "    (model): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (u5): UpConv(\n",
       "    (convtranspose): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (convlayers): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (u4): UpConv(\n",
       "    (convtranspose): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (convlayers): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (u3): UpConv(\n",
       "    (convtranspose): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (convlayers): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (u2): UpConv(\n",
       "    (convtranspose): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (convlayers): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (u1): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch0",
   "language": "python",
   "name": "torch0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
